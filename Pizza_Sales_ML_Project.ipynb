{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7FOV5Ovyd0gQuu3WHszLs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/summerolmstead/Sales-Prediction/blob/main/Pizza_Sales_ML_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Team Project | Pizza Prediction Sales\n",
        "\n",
        "Summer, Jason, Victoria, Regan"
      ],
      "metadata": {
        "id": "XTXvWQWgEYay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Data in"
      ],
      "metadata": {
        "id": "z2dK6Qscz77K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFx0wi1WEV7u",
        "outputId": "8596d286-ba9a-44f7-dad3-d1e15024f82e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/rhonarosecortez/pizza-sales-dataset/versions/2\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"rhonarosecortez/pizza-sales-dataset\") #importing from kaggle\n",
        "\n",
        "print(\"Path to dataset files:\", path) # path to the file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "dataset_files = os.listdir(path)\n",
        "print(\"Dataset files:\", dataset_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js_8PCSUE3xT",
        "outputId": "38ed4639-8967-4a86-881c-7f9433a72c4e"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset files: ['Pizza Sales Dataset.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "csv_file_path = os.path.join(path, 'Pizza Sales Dataset.csv')\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "print(df.head()) # seeing structure of data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntzNj_aCFD1R",
        "outputId": "f9dd4699-7d1b-4a43-8a64-2996e3941d79"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   pizza_id  order_id  pizza_name_id  quantity order_date order_day  \\\n",
            "0         1         1     hawaiian_m         1   1/1/2015  Thursday   \n",
            "1         2         2  classic_dlx_m         1   1/1/2015  Thursday   \n",
            "2         3         2  five_cheese_l         1   1/1/2015  Thursday   \n",
            "3         4         2    ital_supr_l         1   1/1/2015  Thursday   \n",
            "4         5         2     mexicana_m         1   1/1/2015  Thursday   \n",
            "\n",
            "  order_time  unit_price  total_price pizza_size pizza_category  \\\n",
            "0   11:38:36       13.25        13.25          M        Classic   \n",
            "1   11:57:40       16.00        16.00          M        Classic   \n",
            "2   11:57:40       18.50        18.50          L         Veggie   \n",
            "3   11:57:40       20.75        20.75          L        Supreme   \n",
            "4   11:57:40       16.00        16.00          M         Veggie   \n",
            "\n",
            "                                   pizza_ingredients  \\\n",
            "0           Sliced Ham, Pineapple, Mozzarella Cheese   \n",
            "1  Pepperoni, Mushrooms, Red Onions, Red Peppers,...   \n",
            "2  Mozzarella Cheese, Provolone Cheese, Smoked Go...   \n",
            "3  Calabrese Salami, Capocollo, Tomatoes, Red Oni...   \n",
            "4  Tomatoes, Red Peppers, Jalapeno Peppers, Red O...   \n",
            "\n",
            "                  pizza_name  \n",
            "0         The Hawaiian Pizza  \n",
            "1   The Classic Deluxe Pizza  \n",
            "2      The Five Cheese Pizza  \n",
            "3  The Italian Supreme Pizza  \n",
            "4         The Mexicana Pizza  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all unique values in the 'order_day' column\n",
        "print(df['order_day'].unique())\n",
        "\n",
        "# Print the first few rows of the dataframe to inspect\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Nele00_w1-s",
        "outputId": "61122d03-62cb-4472-c33d-73e8a381579e"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Thursday' 'Friday' 'Saturday' 'Sunday' 'Monday' 'Tuesday' 'Wednesday']\n",
            "   pizza_id  order_id  pizza_name_id  quantity order_date order_day  \\\n",
            "0         1         1     hawaiian_m         1   1/1/2015  Thursday   \n",
            "1         2         2  classic_dlx_m         1   1/1/2015  Thursday   \n",
            "2         3         2  five_cheese_l         1   1/1/2015  Thursday   \n",
            "3         4         2    ital_supr_l         1   1/1/2015  Thursday   \n",
            "4         5         2     mexicana_m         1   1/1/2015  Thursday   \n",
            "\n",
            "  order_time  unit_price  total_price pizza_size pizza_category  \\\n",
            "0   11:38:36       13.25        13.25          M        Classic   \n",
            "1   11:57:40       16.00        16.00          M        Classic   \n",
            "2   11:57:40       18.50        18.50          L         Veggie   \n",
            "3   11:57:40       20.75        20.75          L        Supreme   \n",
            "4   11:57:40       16.00        16.00          M         Veggie   \n",
            "\n",
            "                                   pizza_ingredients  \\\n",
            "0           Sliced Ham, Pineapple, Mozzarella Cheese   \n",
            "1  Pepperoni, Mushrooms, Red Onions, Red Peppers,...   \n",
            "2  Mozzarella Cheese, Provolone Cheese, Smoked Go...   \n",
            "3  Calabrese Salami, Capocollo, Tomatoes, Red Oni...   \n",
            "4  Tomatoes, Red Peppers, Jalapeno Peppers, Red O...   \n",
            "\n",
            "                  pizza_name  \n",
            "0         The Hawaiian Pizza  \n",
            "1   The Classic Deluxe Pizza  \n",
            "2      The Five Cheese Pizza  \n",
            "3  The Italian Supreme Pizza  \n",
            "4         The Mexicana Pizza  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Check of the Data"
      ],
      "metadata": {
        "id": "JWMgIAOh0ANS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe() # seeing summary statistics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "sApAgsQ1PCFl",
        "outputId": "fd9e1f34-d595-4a49-bead-ddd62390925b"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           pizza_id      order_id      quantity    unit_price   total_price\n",
              "count  48620.000000  48620.000000  48620.000000  48620.000000  48620.000000\n",
              "mean   24310.500000  10701.479761      1.019622     16.494132     16.821474\n",
              "std    14035.529381   6180.119770      0.143077      3.621789      4.437398\n",
              "min        1.000000      1.000000      1.000000      9.750000      9.750000\n",
              "25%    12155.750000   5337.000000      1.000000     12.750000     12.750000\n",
              "50%    24310.500000  10682.500000      1.000000     16.500000     16.500000\n",
              "75%    36465.250000  16100.000000      1.000000     20.250000     20.500000\n",
              "max    48620.000000  21350.000000      4.000000     35.950000     83.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2df05af-5d07-4934-87c9-e5cfa50c3b49\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pizza_id</th>\n",
              "      <th>order_id</th>\n",
              "      <th>quantity</th>\n",
              "      <th>unit_price</th>\n",
              "      <th>total_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>48620.000000</td>\n",
              "      <td>48620.000000</td>\n",
              "      <td>48620.000000</td>\n",
              "      <td>48620.000000</td>\n",
              "      <td>48620.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>24310.500000</td>\n",
              "      <td>10701.479761</td>\n",
              "      <td>1.019622</td>\n",
              "      <td>16.494132</td>\n",
              "      <td>16.821474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>14035.529381</td>\n",
              "      <td>6180.119770</td>\n",
              "      <td>0.143077</td>\n",
              "      <td>3.621789</td>\n",
              "      <td>4.437398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.750000</td>\n",
              "      <td>9.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>12155.750000</td>\n",
              "      <td>5337.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>12.750000</td>\n",
              "      <td>12.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>24310.500000</td>\n",
              "      <td>10682.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>16.500000</td>\n",
              "      <td>16.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>36465.250000</td>\n",
              "      <td>16100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>20.250000</td>\n",
              "      <td>20.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>48620.000000</td>\n",
              "      <td>21350.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>35.950000</td>\n",
              "      <td>83.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2df05af-5d07-4934-87c9-e5cfa50c3b49')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f2df05af-5d07-4934-87c9-e5cfa50c3b49 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f2df05af-5d07-4934-87c9-e5cfa50c3b49');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2c9ad63b-94b0-48b7-bd4e-4d40d1365773\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c9ad63b-94b0-48b7-bd4e-4d40d1365773')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2c9ad63b-94b0-48b7-bd4e-4d40d1365773 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"pizza_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17522.57843564067,\n        \"min\": 1.0,\n        \"max\": 48620.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          48620.0,\n          24310.5,\n          36465.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"order_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15141.979335301296,\n        \"min\": 1.0,\n        \"max\": 48620.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          10701.479761415056,\n          10682.5,\n          48620.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quantity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17189.303102156584,\n        \"min\": 0.14307700932475953,\n        \"max\": 48620.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.0196215549156726,\n          4.0,\n          0.14307700932475953\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unit_price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17183.94408523473,\n        \"min\": 3.6217891586575077,\n        \"max\": 48620.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          16.494132044426163,\n          16.5,\n          48620.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17181.512699811075,\n        \"min\": 4.4373975811805755,\n        \"max\": 48620.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          16.821473673385437,\n          16.5,\n          48620.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "zWVDozDr0KJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from datetime import timedelta\n",
        "\n",
        "# Preprocess the date-related columns\n",
        "df['order_date'] = pd.to_datetime(df['order_date'])\n",
        "df['order_day'] = pd.to_datetime(df['order_day'], format='%A').dt.dayofweek\n",
        "\n",
        "# Feature engineering for model input\n",
        "df['month'] = df['order_date'].dt.month\n",
        "df['day'] = df['order_date'].dt.day\n",
        "df['year'] = df['order_date'].dt.year\n",
        "df['weekday'] = df['order_date'].dt.weekday\n",
        "\n",
        "# **New Step**: Aggregate pizza sales by pizza type and date\n",
        "pizza_sales_by_day = df.groupby(['order_date', 'pizza_name']).agg(\n",
        "    total_sales=('total_price', 'sum'),\n",
        "    total_quantity=('quantity', 'sum'),\n",
        "    month=('month', 'first'),\n",
        "    day=('day', 'first'),\n",
        "    year=('year', 'first'),\n",
        "    weekday=('weekday', 'first')\n",
        ").reset_index()\n",
        "\n",
        "# **New Step**: Create lag features based on past month's sales\n",
        "pizza_sales_by_day['lag_1'] = pizza_sales_by_day['total_sales'].shift(1)  # Lag 1: Previous month's sales\n",
        "pizza_sales_by_day['lag_2'] = pizza_sales_by_day['total_sales'].shift(2)  # Lag 2: Two months back sales\n",
        "\n",
        "# Fill NA values resulting from shifting (they'll appear at the start of the dataset)\n",
        "pizza_sales_by_day.fillna(0, inplace=True)\n",
        "\n",
        "# **New Step**: Create pizza ingredient mapping\n",
        "pizza_ingredients_map = df.groupby('pizza_name')['pizza_ingredients'].apply(lambda x: ', '.join(x.unique())).to_dict()\n",
        "\n",
        "# Prepare the feature matrix (X) and target variable (y) for predicting total sales and ingredients\n",
        "X = pizza_sales_by_day[['month', 'day', 'year', 'weekday', 'total_quantity', 'lag_1', 'lag_2']]  # Added lags\n",
        "y_sales = pizza_sales_by_day['total_sales']  # Target: total sales\n",
        "\n",
        "# **New Step**: Prepare ingredient predictions\n",
        "ingredient_predictions = []\n",
        "\n",
        "for _, row in pizza_sales_by_day.iterrows():\n",
        "    pizza_name = row['pizza_name']\n",
        "    ingredients = pizza_ingredients_map.get(pizza_name, '')\n",
        "    ingredient_predictions.append({'order_date': row['order_date'], 'pizza_name': pizza_name, 'ingredients': ingredients})\n",
        "\n",
        "ingredient_df = pd.DataFrame(ingredient_predictions)\n",
        "\n",
        "# Print the first few rows to verify\n",
        "print(\"Pizza Sales by Day (with Lags):\")\n",
        "print(pizza_sales_by_day.head())\n",
        "print(\"\\nIngredient Predictions:\")\n",
        "print(ingredient_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4Hjx6l01iwN",
        "outputId": "27d6aae9-4998-403c-d713-3653a4796649"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pizza Sales by Day (with Lags):\n",
            "  order_date                    pizza_name  total_sales  total_quantity  \\\n",
            "0 2015-01-01    The Barbecue Chicken Pizza       204.25              11   \n",
            "1 2015-01-01            The Big Meat Pizza        60.00               5   \n",
            "2 2015-01-01           The Calabrese Pizza        16.25               1   \n",
            "3 2015-01-01  The California Chicken Pizza        71.00               4   \n",
            "4 2015-01-01     The Chicken Alfredo Pizza        29.50               2   \n",
            "\n",
            "   month  day  year  weekday   lag_1   lag_2  \n",
            "0      1    1  2015        3    0.00    0.00  \n",
            "1      1    1  2015        3  204.25    0.00  \n",
            "2      1    1  2015        3   60.00  204.25  \n",
            "3      1    1  2015        3   16.25   60.00  \n",
            "4      1    1  2015        3   71.00   16.25  \n",
            "\n",
            "Ingredient Predictions:\n",
            "  order_date                    pizza_name  \\\n",
            "0 2015-01-01    The Barbecue Chicken Pizza   \n",
            "1 2015-01-01            The Big Meat Pizza   \n",
            "2 2015-01-01           The Calabrese Pizza   \n",
            "3 2015-01-01  The California Chicken Pizza   \n",
            "4 2015-01-01     The Chicken Alfredo Pizza   \n",
            "\n",
            "                                         ingredients  \n",
            "0  Barbecued Chicken, Red Peppers, Green Peppers,...  \n",
            "1  Bacon, Pepperoni, Italian Sausage, Chorizo Sau...  \n",
            "2  ?duja Salami, Pancetta, Tomatoes, Red Onions, ...  \n",
            "3  Chicken, Artichoke, Spinach, Garlic, Jalapeno ...  \n",
            "4  Chicken, Red Onions, Red Peppers, Mushrooms, A...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper Parameter Tuning"
      ],
      "metadata": {
        "id": "FSaExH_AKROS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "\n",
        "# Define the parameter distribution\n",
        "param_dist = {\n",
        "    'learning_rate': np.arange(0.01, 0.2, 0.01),\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.7, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Define the model\n",
        "model = xgb.XGBRegressor(objective='reg:squarederror')\n",
        "\n",
        "# RandomizedSearchCV with detailed output\n",
        "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist,\n",
        "                                   n_iter=10, cv=5, scoring='neg_mean_absolute_error',\n",
        "                                   random_state=42, n_jobs=-1, verbose=3)\n",
        "\n",
        "# Fit the model\n",
        "random_search.fit(X, y_sales)  # X and y_sales are your features and target for sales prediction\n",
        "\n",
        "# Get the best hyperparameters\n",
        "print(f\"Best hyperparameters: {random_search.best_params_}\")\n",
        "\n",
        "# Use the best model\n",
        "best_model = random_search.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "8JUTkk7fKQ54",
        "outputId": "1734e75f-d275-4361-b39e-4061dee26ba8"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-157-f6f3ab3bcece>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_sales\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# X and y_sales are your features and target for sales prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Get the best hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1951\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1952\u001b[0m             ParameterSampler(\n\u001b[1;32m   1953\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     )\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    971\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Model"
      ],
      "metadata": {
        "id": "2FaOkT_9KPiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split for sales forecasting\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_sales, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train XGBoost model for total sales forecasting\n",
        "model_sales = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=200, max_depth=5, learning_rate=0.13)\n",
        "model_sales.fit(X_train, y_train)\n",
        "\n",
        "# Predicting on test data for sales\n",
        "y_pred_sales = model_sales.predict(X_test)\n",
        "mae_sales = mean_absolute_error(y_test, y_pred_sales)\n",
        "print(f'Mean Absolute Error for Sales Prediction: {mae_sales}')\n",
        "\n",
        "# Forecasting the next 30 days of pizza sales\n",
        "future_dates = pd.date_range(pizza_sales_by_day['order_date'].max(), periods=31, freq='D')[1:]  # Next 30 days\n",
        "future_features = pd.DataFrame({\n",
        "    'month': future_dates.month,\n",
        "    'day': future_dates.day,\n",
        "    'year': future_dates.year,\n",
        "    'weekday': future_dates.weekday,\n",
        "    'total_quantity': np.zeros(30),  # You can set this to zeros or an estimated value\n",
        "    'lag_1': np.zeros(30),  # You can set this based on previous month's prediction\n",
        "    'lag_2': np.zeros(30),  # Similarly, based on two months prior\n",
        "})\n",
        "\n",
        "# Predict future sales\n",
        "future_sales = model_sales.predict(future_features)\n",
        "\n",
        "# Prepare a DataFrame for the future sales predictions\n",
        "future_sales_df = pd.DataFrame({\n",
        "    'order_date': future_dates,\n",
        "    'predicted_total_sales': future_sales\n",
        "})\n",
        "\n",
        "# Display the predicted future sales\n",
        "print(future_sales_df)\n",
        "\n",
        "# Step 1: Calculate the historical sales for each pizza type because we want dynamic percentage points\n",
        "# Assuming you have a DataFrame `pizza_sales_by_day` with 'pizza_name' and 'sales' columns\n",
        "pizza_sales_by_pizza = pizza_sales_by_day.groupby('pizza_name')['total_sales'].sum()  # Use 'total_sales' column\n",
        "\n",
        "# Calculate the total sales across all pizzas\n",
        "total_sales = pizza_sales_by_pizza.sum()\n",
        "\n",
        "# Now calculate the percentage of total sales for each pizza\n",
        "pizza_sales_percentage = pizza_sales_by_pizza / total_sales\n",
        "\n",
        "# Check the calculated percentages for each pizza\n",
        "print(pizza_sales_percentage)\n",
        "\n",
        "# Predict ingredients for the future dates\n",
        "ingredient_predictions_future = []\n",
        "\n",
        "for date in future_dates:\n",
        "    # Get the sales forecast for each pizza type\n",
        "    daily_ingredients = []\n",
        "    predicted_sales = future_sales_df.loc[future_sales_df['order_date'] == date, 'predicted_total_sales'].values[0]\n",
        "\n",
        "    # Loop over each pizza in the historical pizza list\n",
        "    for pizza_name in pizza_ingredients_map:\n",
        "        # Get the historical sales percentage for this pizza\n",
        "        pizza_percentage = pizza_sales_percentage.get(pizza_name, 0)  # Default to 0 if not found\n",
        "\n",
        "        # Predicted sales for this pizza is the historical percentage * predicted total sales\n",
        "        predicted_sales_for_pizza = pizza_percentage * predicted_sales\n",
        "\n",
        "        ingredients = pizza_ingredients_map.get(pizza_name, '')\n",
        "        if ingredients:\n",
        "            daily_ingredients.append(f\"{pizza_name}: {ingredients} ({pizza_percentage:.2%} of sales, {predicted_sales_for_pizza:.2f} sales)\")\n",
        "\n",
        "    ingredient_predictions_future.append({'date': date, 'ingredients': ', '.join(daily_ingredients)})\n",
        "\n",
        "# Create a DataFrame to view the ingredient predictions for future dates\n",
        "ingredient_df_future = pd.DataFrame(ingredient_predictions_future)\n",
        "\n",
        "# Display the predicted ingredients\n",
        "print(ingredient_df_future)"
      ],
      "metadata": {
        "id": "u74qhgRmJ57-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the columns of future_sales_df to see if the date information is already in a single column\n",
        "print(future_sales_df.columns)\n"
      ],
      "metadata": {
        "id": "yLchtgqv4xU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'order_date' column to datetime format\n",
        "future_sales_df['order_date'] = pd.to_datetime(future_sales_df['order_date'])\n",
        "# Merge sales data with ingredient predictions for future dates (e.g., January 2016)\n",
        "merged_df = pd.merge(future_sales_df[['order_date', 'predicted_total_sales']], ingredient_df_future, left_on='order_date', right_on='date', how='left')\n",
        "\n",
        "# Drop the 'date' column since it's redundant after merging\n",
        "merged_df = merged_df.drop(columns=['date'])\n",
        "\n",
        "# Display the merged data (sales and ingredient predictions)\n",
        "print(merged_df)"
      ],
      "metadata": {
        "id": "ePSUeFPV4npS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot predicted sales for January 2016\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(merged_df['order_date'], merged_df['predicted_total_sales'], color='skyblue')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Predicted Total Sales')\n",
        "plt.title('Predicted Total Sales for January 2016')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JThvH_oE5QeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ensure the 'order_date' column is in datetime format\n",
        "pizza_sales_by_day['order_date'] = pd.to_datetime(pizza_sales_by_day['order_date'])\n",
        "\n",
        "# Add month and year columns for grouping\n",
        "pizza_sales_by_day['month'] = pizza_sales_by_day['order_date'].dt.month\n",
        "pizza_sales_by_day['year'] = pizza_sales_by_day['order_date'].dt.year\n",
        "\n",
        "# Filter the actual sales data for 2015\n",
        "actual_sales_2015 = pizza_sales_by_day[pizza_sales_by_day['year'] == 2015].groupby(['month']).agg(\n",
        "    actual_sales=('total_sales', 'mean')  # Using total_sales as actual sales\n",
        ").reset_index()\n",
        "\n",
        "# Filter the predicted sales data for 2016\n",
        "predicted_sales_2016 = merged_df[merged_df['year'] == 2016].groupby(['month']).agg(\n",
        "    predicted_sales=('predicted_total_sales', 'mean')\n",
        ").reset_index()\n",
        "\n",
        "# Merge the two datasets on the month column to plot them together\n",
        "monthly_sales = pd.merge(actual_sales_2015, predicted_sales_2016, on='month', how='outer')\n",
        "\n",
        "# Plot the monthly average sales for 2015 and 2016\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot actual sales for 2015\n",
        "plt.plot(monthly_sales['month'], monthly_sales['actual_sales'], label='Actual Sales (2015)', color='blue', marker='o')\n",
        "\n",
        "# Plot predicted sales for 2016\n",
        "plt.plot(monthly_sales['month'], monthly_sales['predicted_sales'], label='Predicted Sales (2016)', color='red', marker='o')\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Average Sales')\n",
        "plt.title('Monthly Average Sales: 2015 vs Predicted 2016')\n",
        "plt.xticks(range(1, 13))  # Set x-axis to show month numbers\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XqvgvvlME9fe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}